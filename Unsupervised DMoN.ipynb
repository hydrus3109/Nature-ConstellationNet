{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpJxvJoEJpeO",
    "outputId": "64cb53e4-0852-4b11-cb99-ac6665d61596"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from numpy.linalg import norm\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "#GNN stuff\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import umap\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By0LPq0vJpeP"
   },
   "source": [
    "Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyLdLSevJpeQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "#taken from the google research DMoN paper\n",
    "def precision(y_true, y_pred):\n",
    "  true_positives, false_positives, _, _ = _compute_counts(y_true, y_pred)\n",
    "  return true_positives / (true_positives + false_positives)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "  true_positives, _, false_negatives, _ = _compute_counts(y_true, y_pred)\n",
    "  return true_positives / (true_positives + false_negatives)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "  true_positives, false_positives, false_negatives, true_negatives = _compute_counts(\n",
    "      y_true, y_pred)\n",
    "  return (true_positives + true_negatives) / (\n",
    "      true_positives + false_positives + false_negatives + true_negatives)\n",
    "\n",
    "\n",
    "def _compute_counts(y_true, y_pred):  \n",
    "  contingency = contingency_matrix(y_true, y_pred)\n",
    "  same_class_true = np.max(contingency, 1)\n",
    "  same_class_pred = np.max(contingency, 0)\n",
    "  diff_class_true = contingency.sum(axis=1) - same_class_true\n",
    "  diff_class_pred = contingency.sum(axis=0) - same_class_pred\n",
    "  total = contingency.sum()\n",
    "\n",
    "  true_positives = (same_class_true * (same_class_true - 1)).sum()\n",
    "  false_positives = (diff_class_true * same_class_true * 2).sum()\n",
    "  false_negatives = (diff_class_pred * same_class_pred * 2).sum()\n",
    "  true_negatives = total * (\n",
    "      total - 1) - true_positives - false_positives - false_negatives\n",
    "\n",
    "  return true_positives, false_positives, false_negatives, true_negatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MnkJCmlJpeQ"
   },
   "source": [
    "Load High dimen MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cuUJQgYJpeQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70000, 784])\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load('HighDimenData/mnist.npy')\n",
    "file_path = 'HighDimenData/mnist.gt'\n",
    "labels = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        labels.append(int(line.strip()))\n",
    "\n",
    "#labels = np.load('/notebooks/SVHNdinollabels.npy')\n",
    "labels= torch.tensor(labels)\n",
    "dataset = torch.from_numpy(dataset)\n",
    "print(dataset.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Kmeans block to use with either the DINO dataset or GNN embedded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "print(time.time()-start)\n",
    "dataset = dataset.reshape(dataset.shape[0], -1)\n",
    "model= KMeans(n_clusters= 101, random_state=0, n_init=\"auto\").fit(dataset)\n",
    "hdbscan_labels = model.fit_predict(dataset)\n",
    "print(time.time()-start)\n",
    "print(adjusted_rand_score(labels, hdbscan_labels))\n",
    "print(adjusted_mutual_info_score(labels, hdbscan_labels))\n",
    "print(accuracy_score(labels, hdbscan_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raB6PgAHJpeQ"
   },
   "source": [
    "Neighbor graph gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GZCLKg9FJpeR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "#5\n",
    "k = 50\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(dataset)\n",
    "distances, indices = nbrs.kneighbors(dataset)\n",
    "\n",
    "# Calculate inverse distances, with a small epsilon to avoid division by zero\n",
    "epsilon = 1e-5\n",
    "inverse_distances = 1 / (distances.flatten() + epsilon)\n",
    "\n",
    "num_nodes = indices.shape[0]\n",
    "source_nodes = np.repeat(np.arange(num_nodes), k)\n",
    "target_nodes = indices.flatten()\n",
    "edge_index = np.vstack([source_nodes, target_nodes])\n",
    "np.save('edgeindex30k.npy',edge_index)\n",
    "edge_index = torch.from_numpy(edge_index).long()\n",
    "edge_weight = torch.from_numpy(inverse_distances).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vUD0-Vx-JpeR"
   },
   "outputs": [],
   "source": [
    "train_mask = np.zeros(num_nodes, dtype=bool)\n",
    "train_mask[:70000] = True\n",
    "\n",
    "# Creating the test mask\n",
    "test_mask = np.zeros(num_nodes, dtype=bool)\n",
    "test_mask[20000:] = True\n",
    "\n",
    "train_mask = torch.from_numpy(train_mask)\n",
    "test_mask = torch.from_numpy(test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "dataset = umap.UMAP(\n",
    "    n_neighbors=50,\n",
    "    min_dist=0.0,\n",
    "    n_components=512,\n",
    "    random_state=42,\n",
    ").fit_transform(dataset)\n",
    "#np.save('umapmnist.npy', dataset)\n",
    "#np.save('umapmnistlabels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y5y66fgFJpeR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 0, 1,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.loader import RandomNodeLoader\n",
    "from torch_geometric.data import Data\n",
    "data = Data(x=dataset, edge_index=edge_index, edge_weight = edge_weight, y = labels, train_mask = train_mask, test_mask = test_mask)\n",
    "#30\n",
    "train_loader = NeighborLoader(data, input_nodes = data.train_mask, num_neighbors=[30]*2, shuffle=True, num_workers = 2, batch_size =64)\n",
    "test_loader = NeighborLoader(data,input_nodes= data.test_mask, num_neighbors=[-1], shuffle=False, num_workers = 2,batch_size = 32)\n",
    "sampled_hetero_data = next(iter(train_loader))\n",
    "print(sampled_hetero_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xqt4kqg6wzT9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, GCNConv\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import DenseGraphConv, DMoNPooling, GCNConv\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout_rate=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.pool = DMoNPooling([hidden_channels, hidden_channels], out_channels)\n",
    "        # Initial GAT layer\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, add_self_loops=True))\n",
    "        self.batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # Hidden GAT layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels, add_self_loops=True))\n",
    "            self.batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # Final GAT layer\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, add_self_loops=True))\n",
    "        self.batch_norms.append(BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv, batch_norm in zip(self.convs[:-1], self.batch_norms[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "            #print(x.size())\n",
    "\n",
    "       # x = self.convs[-1](x, edge_index, edge_attr = edge_attr)\n",
    "        adj = to_dense_adj(edge_index)\n",
    "        #print(x.size())\n",
    "        x, _, adj, sp1, o1, c1 = self.pool(x, adj)\n",
    "        #print(x.size())\n",
    "\n",
    "        return F.log_softmax(x, dim=-1), sp1 + o1 + c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPf8Y4snJpeR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import DenseGraphConv, DMoNPooling, GCNConv\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout_rate=0.5):\n",
    "        super(GAT, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.pool = DMoNPooling([hidden_channels, hidden_channels], out_channels)\n",
    "        # Initial GAT layer\n",
    "        self.convs.append(GATConv(in_channels, hidden_channels, add_self_loops=True))\n",
    "        self.batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # Hidden GAT layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATConv(hidden_channels, hidden_channels, add_self_loops=True))\n",
    "            self.batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # Final GAT layer\n",
    "        self.convs.append(GATConv(hidden_channels, out_channels, add_self_loops=True))\n",
    "        self.batch_norms.append(BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv, batch_norm in zip(self.convs[:-1], self.batch_norms[:-1]):\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "\n",
    "       # x = self.convs[-1](x, edge_index, edge_attr = edge_attr)\n",
    "        adj = to_dense_adj(edge_index)\n",
    "       # print(x.size())\n",
    "        x, _, adj, sp1, o1, c1 = self.pool(x, adj)\n",
    "       # print(x.size())\n",
    "\n",
    "        return F.log_softmax(x, dim=-1), sp1 + o1 + c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD-mbRwcJpeR"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = GAT(in_channels= 1024, hidden_channels=128, out_channels=10, num_layers=5, dropout_rate=0.3).to(device)\n",
    "model = GCN(in_channels= 784, hidden_channels=625, out_channels=10, num_layers=5, dropout_rate=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience= 3, factor = 0.75)\n",
    "#use this for GNN embedding\n",
    "#model.load_state_dict(torch.load('/notebooks/gcnmodel_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Code to further embedd data using a pretrained GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import  NodeLoader\n",
    "from torch_geometric.sampler import BaseSampler, NeighborSampler\n",
    "from torch_geometric.data import Data\n",
    "data = Data(x=dataset, edge_index=edge_index, edge_weight = edge_weight, y = labels).to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "batch_size = 128\n",
    "sampler = NeighborSampler(data,[0])\n",
    "node_loader = NodeLoader(data, sampler,batch_size=batch_size, shuffle=False)\n",
    "# To store the transformed dataset\n",
    "transformed_data = np.array([], dtype=np.int32).reshape(0,256)\n",
    "print(np.shape(transformed_data))\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for batch in node_loader:\n",
    "        batch = batch.to(device)\n",
    "        inputs = batch.x  # Get the inputs from the batch\n",
    "        #print(inputs.size())\n",
    "        outputs = model(batch.x, batch.edge_index, batch.edge_weight)  # Pass the inputs through the model\n",
    "        #print(outputs.size())\n",
    "        transformed_data = np.vstack([transformed_data, outputs.cpu()])\n",
    "        #print(np.shape(transformed_data))\n",
    "\n",
    "\n",
    "print(\"Transformed dataset shape:\", np.shape( transformed_data))\n",
    "np.save('GNNtransformed.npy', transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LgHu8GuyJpeS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class lossmodel(nn.Module):\n",
    "    def __init__(self, n_clusters, dropout_rate = 0):\n",
    "        super(lossmodel, self).__init__()\n",
    "        self.n_clusters = n_clusters\n",
    "        self.dropout_rate = 0\n",
    "\n",
    "        # Define the layers\n",
    "        self.transform = nn.Sequential(\n",
    "            nn.Linear(n_clusters, n_clusters),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.orthogonal_(self.transform[0].weight)\n",
    "        nn.init.zeros_(self.transform[0].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transform(x)\n",
    "\n",
    "\n",
    "def calculate_collapse_loss(number_of_nodes, n_clusters, output, lossize):\n",
    "    model = lossmodel(n_clusters).to(device)\n",
    "    assignments = F.softmax(model(output), dim=1)\n",
    "    cluster_sizes = torch.sum(assignments, dim=0)\n",
    "    collapse_loss = torch.norm(cluster_sizes) / number_of_nodes * torch.sqrt(torch.tensor(float(n_clusters))) - 1\n",
    "    return collapse_loss*lossize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "mWk0RSVMKcvz",
    "outputId": "faac5327-3f5d-4145-b115-850a816596b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ty7enxz6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GIN-UMAP</strong> at: <a href='https://wandb.ai/aidan_research/PRIMES-GNN/runs/ty7enxz6' target=\"_blank\">https://wandb.ai/aidan_research/PRIMES-GNN/runs/ty7enxz6</a><br/> View project at: <a href='https://wandb.ai/aidan_research/PRIMES-GNN' target=\"_blank\">https://wandb.ai/aidan_research/PRIMES-GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240710_203604-ty7enxz6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ty7enxz6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aidan\\Desktop\\PRIMES-GNN\\High Dimen Testing\\wandb\\run-20240710_203837-pgflnfpk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aidan_research/PRIMES-GNN/runs/pgflnfpk' target=\"_blank\">GIN-highbatch</a></strong> to <a href='https://wandb.ai/aidan_research/PRIMES-GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aidan_research/PRIMES-GNN' target=\"_blank\">https://wandb.ai/aidan_research/PRIMES-GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aidan_research/PRIMES-GNN/runs/pgflnfpk' target=\"_blank\">https://wandb.ai/aidan_research/PRIMES-GNN/runs/pgflnfpk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"architecture\":\"GIN\",\n",
    "    \"clusters\":10,\n",
    "    \"dataset\":\"MNIST\",\n",
    "    \"epochs\":50,\n",
    "    \"hidden_channel\":128,\n",
    "    \"layers\":5,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"loss_function\":\"ALL\",\n",
    "    \"neighbors\":50,\n",
    "}\n",
    "\n",
    "# Pass the config dictionary when you initialize W&B\n",
    "run = wandb.init(project=\"PRIMES-GNN\", config=config, name = 'GIN-highbatch')\n",
    "#e807d0434ea6864dc92d6c99cdcfa073feaca0cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg06gp64JpeS"
   },
   "source": [
    "Neighbor loader with Plateau scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lJa03rVLJpeS",
    "outputId": "2c3a1274-354d-4abe-fb94-e13b2509f255"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m51\u001b[39m):\n\u001b[0;32m     45\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 46\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart)\n\u001b[0;32m     48\u001b[0m     _, train_acc,nmi \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#out,tot_loss = model(data.x, data.edge_index, data.edge_weight)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m out,tot_loss \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n",
      "File \u001b[1;32mc:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\torch_geometric\\data\\data.py:360\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    356\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\torch_geometric\\data\\data.py:340\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 340\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\torch_geometric\\data\\storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\torch_geometric\\data\\storage.py:895\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32mc:\\Users\\aidan\\Desktop\\PRIMES-GNN\\venv\\Lib\\site-packages\\torch_geometric\\data\\data.py:361\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    356\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 361\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch_sparse\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "classes = 10\n",
    "def train():\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    count = 0\n",
    "    for data in train_loader:\n",
    "        count = count+1\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        #out,tot_loss = model(data.x, data.edge_index, data.edge_weight)\n",
    "        out,tot_loss = model(data.x, data.edge_index)\n",
    "        out = out.squeeze()\n",
    "        loss = tot_loss + calculate_collapse_loss(data.num_nodes,classes,out,0.1)\n",
    "        loss_all += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_all/count\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    loss_all = 0\n",
    "    nmi = 0\n",
    "    count = 0\n",
    "    for data in loader:\n",
    "        count +=1\n",
    "        data.to(device)\n",
    "        #pred,tot_loss = model(data.x, data.edge_index, data.edge_weight)\n",
    "        pred,tot_loss = model(data.x, data.edge_index)\n",
    "        pred = pred.squeeze()\n",
    "        loss = tot_loss+ calculate_collapse_loss(data.num_nodes,classes,pred,0.1)\n",
    "        loss_all += loss.item()\n",
    "        correct += accuracy_score(data.y.cpu().detach().numpy(),pred.max(dim=-1)[1].cpu().detach().numpy())\n",
    "        nmi += normalized_mutual_info_score(data.y.cpu().detach().numpy(),pred.max(dim=-1)[1].cpu().detach().numpy())\n",
    "    return loss_all/count, correct/count, nmi/count\n",
    "\n",
    "\n",
    "times = []\n",
    "for epoch in range(1, 51):\n",
    "    start = time.time()\n",
    "    train_loss = train()\n",
    "    print(time.time()-start)\n",
    "    _, train_acc,nmi = test(test_loader)\n",
    "    print(time.time()-start)\n",
    "    test_loss, test_acc,nmi = test(test_loader)\n",
    "    #wandb.log({'acc': test_acc, 'loss': test_loss, \"nmi\": nmi})\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}, '\n",
    "          f'Train Acc: {train_acc:.3f},  '\n",
    "          f' Test Loss: {test_loss:.3f}, '\n",
    "          f'Test Acc: {test_acc:.3f}')\n",
    "    times.append(time.time() - start)\n",
    "    if nmi > best_nmi:\n",
    "        torch.save(model.state_dict(), 'gcnmodel_weights.pth')\n",
    "        best_nmi = nmi\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3q97myTuJpeS"
   },
   "source": [
    "Metrics For eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FogE6h2ZJpeT",
    "outputId": "41e2b0cc-a273-46b7-8562-ede8cd1930a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "def metrics():\n",
    "    model.eval()\n",
    "    avgacc = 0\n",
    "    avgARI = 0\n",
    "    loss_all = 0\n",
    "    avgprec = 0\n",
    "    avgrec = 0\n",
    "    count = 0\n",
    "    avgnmi = 0\n",
    "    for data in test_loader:\n",
    "        count = count +1\n",
    "        data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.edge_weight)\n",
    "        pred = pred.max(dim=-1)[1].cpu().detach().numpy()\n",
    "        pred = pred.squeeze()\n",
    "        labelsfin = data.y.cpu().detach().numpy()\n",
    "        avgacc += accuracy_score(labelsfin,pred)\n",
    "        avgrec += recall(labelsfin,pred)\n",
    "        avgprec +=precision(labelsfin,pred)\n",
    "        avgARI +=adjusted_rand_score(labelsfin,pred)\n",
    "        avgnmi += normalized_mutual_info_score(labelsfin,pred)\n",
    "    print(f\"acc score:{avgacc/count}\")\n",
    "    print(f\"recall score:{avgrec/count}\")\n",
    "    print(f\"precision score:{avgprec/count}\")\n",
    "    print(f\"F1:{2*avgprec*avgrec/(avgprec+avgrec)/count}\")\n",
    "    print(f\"ARI:{avgARI/count}\")\n",
    "    print(f\"NMI:{avgnmi/count}\")\n",
    "metrics()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
